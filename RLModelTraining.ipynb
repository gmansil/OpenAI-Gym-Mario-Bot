{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hZV8VOo3RDJ_jdaWNlrgunNt3MN7LjrX",
      "authorship_tag": "ABX9TyOAcC3ock10FyM3o6r1GYZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmansil/OpenAI-Gym-Mario-Bot/blob/main/RLModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary dependencies \n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install gym[all]\n",
        "!pip install gym_super_mario_bros==7.3.0 nes_py"
      ],
      "metadata": {
        "id": "O_gvEj4XZGJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "import gym\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "# import os for file path management\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "# import PPO for algos\n",
        "from stable_baselines3 import PPO\n",
        "# import base callback for saving models\n",
        "from stable_baselines3.common.callbacks import BaseCallback"
      ],
      "metadata": {
        "id": "wT2O4GXgaTu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import game\n",
        "import gym_super_mario_bros\n",
        "\n",
        "# import Joypad wrapper\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "\n",
        "#import SIMPLIFIED controls\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "\n",
        "# import Frame Stacker wrapper and GrayScaling Wrapper\n",
        "from gym.wrappers import GrayScaleObservation"
      ],
      "metadata": {
        "id": "1EvGERykFfrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.create the base environment \n",
        "env = gym_super_mario_bros.make(\"SuperMarioBros-v0\")\n",
        "# 2.simplify the controls\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "# 3.grayscale \n",
        "env = GrayScaleObservation(env, keep_dim=True)\n",
        "# 4.wrap inside the Dummy Environment \n",
        "env = DummyVecEnv([lambda: env])\n",
        "# 5.stack the frames\n",
        "env = VecFrameStack(env, 4, channels_order=\"last\")"
      ],
      "metadata": {
        "id": "IdSwPOyUGIB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainAndLoggingCallback(BaseCallback):\n",
        "    def __init__(self, check_freq, save_path, verbose=1):\n",
        "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
        "        self.check_freq = check_freq\n",
        "        self.save_path = save_path\n",
        "        \n",
        "    def _init_callback(self):\n",
        "        if self.save_path is not None:\n",
        "            os.makedirs(self.save_path, exist_ok=True)\n",
        "            \n",
        "    def _on_step(self):\n",
        "        if self.n_calls % self.check_freq == 0:\n",
        "            model_path = os.path.join(self.save_path, \"best_model_{}\".format(self.n_calls))\n",
        "            self.model.save(model_path)\n",
        "            \n",
        "        return True"
      ],
      "metadata": {
        "id": "mm_FKlJgGK-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR = \"./train/\"\n",
        "LOG_DIR = \"./logs/\""
      ],
      "metadata": {
        "id": "2-LSxjl2GsNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup model saving callback\n",
        "callback = TrainAndLoggingCallback(check_freq=1000000, save_path=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "N6x0Ry4YGwV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001,\n",
        "           n_steps=512)"
      ],
      "metadata": {
        "id": "EbvuTSMSGzHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model to learn the game\n",
        "model.learn(total_timesteps=100000, callback=callback)"
      ],
      "metadata": {
        "id": "Ng2cE7-IG2Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('recentModel')"
      ],
      "metadata": {
        "id": "aoMrZe1ABFZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}